# ê³ ê¸‰ ì œì¡°ì—… AI í’ˆì§ˆê´€ë¦¬ ëŒ€ì‹œë³´ë“œ
import streamlit as st
import pandas as pd
import numpy as np
import pickle
import joblib
import plotly.graph_objects as go
import plotly.express as px
import plotly.figure_factory as ff
from plotly.subplots import make_subplots
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# ë¨¸ì‹ ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬
from sklearn.ensemble import RandomForestClassifier, IsolationForest
from sklearn.linear_model import LogisticRegression
from sklearn.decomposition import PCA
from sklearn.cluster import DBSCAN
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, f1_score, roc_auc_score
from sklearn.inspection import permutation_importance
from imblearn.over_sampling import SMOTE
import lightgbm as lgb
import xgboost as xgb
from scipy import stats
import shap

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ğŸ­ AI í’ˆì§ˆê´€ë¦¬ ì‹œìŠ¤í…œ",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ê³ ê¸‰ CSS ìŠ¤íƒ€ì¼ë§
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 2rem;
        border-radius: 15px;
        color: white;
        text-align: center;
        margin-bottom: 2rem;
        box-shadow: 0 10px 30px rgba(0,0,0,0.3);
    }
    .metric-card {
        background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
        padding: 1.5rem;
        border-radius: 12px;
        box-shadow: 0 4px 15px rgba(0,0,0,0.1);
        border-left: 5px solid #667eea;
        margin: 1rem 0;
    }
    .anomaly-card {
        background: linear-gradient(135deg, #ff9a9e 0%, #fecfef 100%);
        border-left: 5px solid #ff6b6b;
        padding: 1.5rem;
        border-radius: 12px;
        margin: 1rem 0;
        animation: pulse 2s infinite;
    }
    .normal-card {
        background: linear-gradient(135deg, #a8edea 0%, #fed6e3 100%);
        border-left: 5px solid #51cf66;
        padding: 1.5rem;
        border-radius: 12px;
        margin: 1rem 0;
    }
    .info-card {
        background: linear-gradient(135deg, #d299c2 0%, #fef9d7 100%);
        border-left: 5px solid #ffd43b;
        padding: 1.5rem;
        border-radius: 12px;
        margin: 1rem 0;
    }
    @keyframes pulse {
        0% { transform: scale(1); }
        50% { transform: scale(1.02); }
        100% { transform: scale(1); }
    }
    .stSelectbox > div > div {
        background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
    }
    .sidebar .sidebar-content {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    }
</style>
""", unsafe_allow_html=True)

@st.cache_data
def load_sample_data():
    """ìƒ˜í”Œ ë°ì´í„° ìƒì„± (ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” ì‹¤ì‹œê°„ ë°ì´í„° ì—°ë™)"""
    np.random.seed(42)
    
    # ì‹œê³„ì—´ ë°ì´í„° ìƒì„± (ìµœê·¼ 30ì¼)
    dates = pd.date_range(start=datetime.now() - timedelta(days=30), 
                         end=datetime.now(), freq='H')
    
    n_samples = len(dates)
    
    # ê¸°ë³¸ ê³µì • ë³€ìˆ˜ë“¤
    data = {
        'timestamp': dates,
        'cast_pressure': np.random.normal(125, 15, n_samples),
        'upper_mold_temp1': np.random.normal(225, 20, n_samples),
        'lower_mold_temp1': np.random.normal(220, 18, n_samples),
        'sleeve_temperature': np.random.normal(195, 25, n_samples),
        'Coolant_temperature': np.random.normal(25, 3, n_samples),
        'low_section_speed': np.random.normal(2.5, 0.5, n_samples),
        'production_cycletime': np.random.normal(40, 5, n_samples),
        'molten_volume': np.random.normal(25, 3, n_samples),
        'physical_strength': np.random.normal(375, 30, n_samples)
    }
    
    # ì´ìƒì¹˜ ì¼ë¶€ ì¶”ê°€
    anomaly_indices = np.random.choice(n_samples, size=int(n_samples*0.05), replace=False)
    data['cast_pressure'][anomaly_indices] += np.random.normal(100, 20, len(anomaly_indices))
    data['sleeve_temperature'][anomaly_indices] += np.random.normal(200, 50, len(anomaly_indices))
    
    # í’ˆì§ˆ ë¼ë²¨ ìƒì„± (ë³µì¡í•œ ë£° ê¸°ë°˜)
    quality_scores = []
    for i in range(n_samples):
        score = 0
        if 100 <= data['cast_pressure'][i] <= 150: score += 2
        if abs(data['upper_mold_temp1'][i] - data['lower_mold_temp1'][i]) < 15: score += 1
        if data['sleeve_temperature'][i] < 400: score += 1
        if data['physical_strength'][i] > 350: score += 1
        
        # ë…¸ì´ì¦ˆ ì¶”ê°€
        score += np.random.choice([-1, 0, 1], p=[0.1, 0.7, 0.2])
        quality_scores.append(1 if score >= 3 else 0)
    
    data['quality'] = quality_scores
    
    return pd.DataFrame(data)

@st.cache_resource
def load_models():
    """ëª¨ë¸ë“¤ ë¡œë“œ ë˜ëŠ” ìƒì„±"""
    try:
        # ê¸°ì¡´ ëª¨ë¸ ë¡œë“œ ì‹œë„
        timestamp = "20250527_153117"
        model_path = f"models/random_forest_model_{timestamp}.joblib"
        model = joblib.load(model_path)
        
        preprocessing_path = f"models/preprocessing_{timestamp}.pkl"
        with open(preprocessing_path, 'rb') as f:
            preprocessing_data = pickle.load(f)
        
        return {
            'classification_model': model,
            'feature_columns': preprocessing_data['feature_columns'],
            'label_encoders': preprocessing_data['label_encoders']
        }
    except:
        # ëª¨ë¸ì´ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
        st.warning("ê¸°ì¡´ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìƒ˜í”Œ ë°ì´í„°ë¡œ ìƒˆ ëª¨ë¸ì„ ìƒì„±í•©ë‹ˆë‹¤.")
        return create_new_models()

def create_new_models():
    """ìƒˆë¡œìš´ ëª¨ë¸ë“¤ ìƒì„±"""
    data = load_sample_data()
    
    # íŠ¹ì„± ì„ íƒ
    feature_cols = ['cast_pressure', 'upper_mold_temp1', 'lower_mold_temp1', 
                   'sleeve_temperature', 'Coolant_temperature', 'low_section_speed',
                   'production_cycletime', 'molten_volume', 'physical_strength']
    
    X = data[feature_cols]
    y = data['quality']
    
    # ë¶„ë¥˜ ëª¨ë¸ í›ˆë ¨
    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
    rf_model.fit(X, y)
    
    return {
        'classification_model': rf_model,
        'feature_columns': feature_cols,
        'label_encoders': {}
    }

class AnomalyDetector:
    """ì´ìƒ íƒì§€ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.scaler = StandardScaler()
        self.pca = PCA(n_components=0.95)
        self.isolation_forest = IsolationForest(contamination=0.1, random_state=42)
        self.dbscan = DBSCAN(eps=0.5, min_samples=5)
        self.is_fitted = False
    
    def fit(self, X):
        """ì´ìƒ íƒì§€ ëª¨ë¸ í›ˆë ¨"""
        X_scaled = self.scaler.fit_transform(X)
        self.pca.fit(X_scaled)
        X_pca = self.pca.transform(X_scaled)
        
        self.isolation_forest.fit(X_scaled)
        self.dbscan.fit(X_pca)
        self.is_fitted = True
        
        return self
    
    def detect_anomalies(self, X):
        """ì´ìƒ íƒì§€ ìˆ˜í–‰"""
        if not self.is_fitted:
            raise ValueError("ëª¨ë¸ì´ í›ˆë ¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        X_scaled = self.scaler.transform(X)
        X_pca = self.pca.transform(X_scaled)
        
        # Z-score ê¸°ë°˜ ì´ìƒ íƒì§€
        z_scores = np.abs(stats.zscore(X_scaled, axis=0))
        z_anomalies = (z_scores > 3).any(axis=1)
        
        # Isolation Forest ì´ìƒ íƒì§€
        iso_anomalies = self.isolation_forest.predict(X_scaled) == -1
        
        # DBSCAN ì´ìƒ íƒì§€
        dbscan_labels = self.dbscan.fit_predict(X_pca)
        dbscan_anomalies = dbscan_labels == -1
        
        # ì¢…í•© ì´ìƒ ì ìˆ˜ (0-1)
        anomaly_scores = (z_anomalies.astype(int) + 
                         iso_anomalies.astype(int) + 
                         dbscan_anomalies.astype(int)) / 3
        
        return {
            'anomaly_scores': anomaly_scores,
            'z_anomalies': z_anomalies,
            'iso_anomalies': iso_anomalies,
            'dbscan_anomalies': dbscan_anomalies,
            'is_anomaly': anomaly_scores > 0.5
        }

def create_anomaly_detection_charts(data, anomaly_results):
    """ì´ìƒ íƒì§€ ì‹œê°í™”"""
    
    # ì´ìƒ ì ìˆ˜ ì‹œê³„ì—´
    fig1 = go.Figure()
    
    colors = ['red' if x else 'green' for x in anomaly_results['is_anomaly']]
    
    fig1.add_trace(go.Scatter(
        x=data['timestamp'],
        y=anomaly_results['anomaly_scores'],
        mode='markers+lines',
        marker=dict(color=colors, size=8),
        name='ì´ìƒ ì ìˆ˜',
        line=dict(width=2)
    ))
    
    fig1.add_hline(y=0.5, line_dash="dash", line_color="red", 
                   annotation_text="ì´ìƒ ì„ê³„ê°’")
    
    fig1.update_layout(
        title="ğŸš¨ ì‹¤ì‹œê°„ ì´ìƒ íƒì§€ ëª¨ë‹ˆí„°ë§",
        xaxis_title="ì‹œê°„",
        yaxis_title="ì´ìƒ ì ìˆ˜",
        height=400,
        showlegend=True
    )
    
    # PCA ì‹œê°í™”
    scaler = StandardScaler()
    pca = PCA(n_components=2)
    
    feature_cols = ['cast_pressure', 'upper_mold_temp1', 'lower_mold_temp1', 
                   'sleeve_temperature', 'Coolant_temperature']
    X_scaled = scaler.fit_transform(data[feature_cols])
    X_pca = pca.fit_transform(X_scaled)
    
    fig2 = go.Figure()
    
    normal_mask = ~anomaly_results['is_anomaly']
    anomaly_mask = anomaly_results['is_anomaly']
    
    fig2.add_trace(go.Scatter(
        x=X_pca[normal_mask, 0],
        y=X_pca[normal_mask, 1],
        mode='markers',
        marker=dict(color='green', size=8, opacity=0.6),
        name='ì •ìƒ'
    ))
    
    fig2.add_trace(go.Scatter(
        x=X_pca[anomaly_mask, 0],
        y=X_pca[anomaly_mask, 1],
        mode='markers',
        marker=dict(color='red', size=12, symbol='x'),
        name='ì´ìƒ'
    ))
    
    fig2.update_layout(
        title="ğŸ” PCA ê¸°ë°˜ ì´ìƒ íƒì§€ ì‹œê°í™”",
        xaxis_title=f"PC1 ({pca.explained_variance_ratio_[0]:.1%} ì„¤ëª…)",
        yaxis_title=f"PC2 ({pca.explained_variance_ratio_[1]:.1%} ì„¤ëª…)",
        height=400
    )
    
    return fig1, fig2

def create_quality_prediction_interface(models):
    """í’ˆì§ˆ ì˜ˆì¸¡ ì¸í„°í˜ì´ìŠ¤"""
    
    st.subheader("ğŸ¯ ì‹¤ì‹œê°„ í’ˆì§ˆ ì˜ˆì¸¡")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**ì£¼ìš” ê³µì • ë³€ìˆ˜**")
        cast_pressure = st.slider("ì£¼ì¡°ì••ë ¥", 80.0, 300.0, 125.0, 1.0)
        upper_temp = st.slider("ìƒë¶€ëª°ë“œì˜¨ë„", 150.0, 350.0, 225.0, 1.0)
        lower_temp = st.slider("í•˜ë¶€ëª°ë“œì˜¨ë„", 150.0, 350.0, 220.0, 1.0)
        sleeve_temp = st.slider("ìŠ¬ë¦¬ë¸Œì˜¨ë„", 150.0, 500.0, 195.0, 1.0)
        coolant_temp = st.slider("ëƒ‰ê°ìˆ˜ì˜¨ë„", 15.0, 40.0, 25.0, 0.5)
    
    with col2:
        st.write("**ë³´ì¡° ê³µì • ë³€ìˆ˜**")
        low_speed = st.slider("ì €ì†êµ¬ê°„ì†ë„", 0.5, 5.0, 2.5, 0.1)
        cycle_time = st.slider("ìƒì‚°ì‚¬ì´í´íƒ€ì„", 25, 60, 40, 1)
        molten_vol = st.slider("ìš©íƒ•ëŸ‰", 15.0, 40.0, 25.0, 0.5)
        strength = st.slider("ë¬¼ë¦¬ê°•ë„", 250.0, 500.0, 375.0, 1.0)
    
    # ì˜ˆì¸¡ ë²„íŠ¼
    if st.button("ğŸ” í’ˆì§ˆ ì˜ˆì¸¡ ì‹¤í–‰", type="primary"):
        
        # ì…ë ¥ ë°ì´í„° êµ¬ì„±
        input_data = np.array([[cast_pressure, upper_temp, lower_temp, sleeve_temp, 
                              coolant_temp, low_speed, cycle_time, molten_vol, strength]])
        
        # ì˜ˆì¸¡ ìˆ˜í–‰
        prediction = models['classification_model'].predict(input_data)[0]
        probability = models['classification_model'].predict_proba(input_data)[0]
        
        # ê²°ê³¼ í‘œì‹œ
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if prediction == 1:
                st.markdown("""
                <div class="normal-card">
                    <h3>âœ… ì˜ˆì¸¡ ê²°ê³¼: ì–‘í’ˆ</h3>
                    <p><strong>í•©ê²© í™•ë¥ :</strong> {:.1%}</p>
                </div>
                """.format(probability[1]), unsafe_allow_html=True)
            else:
                st.markdown("""
                <div class="anomaly-card">
                    <h3>âŒ ì˜ˆì¸¡ ê²°ê³¼: ë¶ˆëŸ‰í’ˆ</h3>
                    <p><strong>ë¶ˆí•©ê²© í™•ë¥ :</strong> {:.1%}</p>
                </div>
                """.format(probability[0]), unsafe_allow_html=True)
        
        with col2:
            # í™•ë¥  ê²Œì´ì§€
            fig_gauge = go.Figure(go.Indicator(
                mode = "gauge+number",
                value = probability[1] * 100,
                title = {'text': "í•©ê²© í™•ë¥  (%)"},
                gauge = {
                    'axis': {'range': [None, 100]},
                    'bar': {'color': "darkgreen" if prediction == 1 else "darkred"},
                    'steps': [
                        {'range': [0, 50], 'color': "lightgray"},
                        {'range': [50, 80], 'color': "yellow"},
                        {'range': [80, 100], 'color': "lightgreen"}
                    ],
                    'threshold': {
                        'line': {'color': "red", 'width': 4},
                        'thickness': 0.75,
                        'value': 90
                    }
                }
            ))
            fig_gauge.update_layout(height=300)
            st.plotly_chart(fig_gauge, use_container_width=True)
        
        with col3:
            # íŠ¹ì„± ì¤‘ìš”ë„
            try:
                importances = models['classification_model'].feature_importances_
                feature_names = ['ì£¼ì¡°ì••ë ¥', 'ìƒë¶€ì˜¨ë„', 'í•˜ë¶€ì˜¨ë„', 'ìŠ¬ë¦¬ë¸Œì˜¨ë„', 
                               'ëƒ‰ê°ìˆ˜ì˜¨ë„', 'ì €ì†', 'ì‚¬ì´í´', 'ìš©íƒ•ëŸ‰', 'ê°•ë„']
                
                fig_imp = go.Figure(go.Bar(
                    x=importances,
                    y=feature_names,
                    orientation='h',
                    marker_color='skyblue'
                ))
                fig_imp.update_layout(
                    title="íŠ¹ì„± ì¤‘ìš”ë„",
                    height=300,
                    margin=dict(l=100)
                )
                st.plotly_chart(fig_imp, use_container_width=True)
            except:
                st.info("íŠ¹ì„± ì¤‘ìš”ë„ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

def create_advanced_analytics():
    """ê³ ê¸‰ ë¶„ì„ ê¸°ëŠ¥"""
    
    st.subheader("ğŸ“Š ê³ ê¸‰ í’ˆì§ˆ ë¶„ì„")
    
    # íƒ­ ìƒì„±
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ” SHAP ë¶„ì„", "ğŸ“ˆ Permutation Importance", 
                                     "ğŸ¯ PDP ë¶„ì„", "âš–ï¸ ëª¨ë¸ ë¹„êµ"])
    
    with tab1:
        st.write("**SHAP (SHapley Additive exPlanations) ë¶„ì„**")
        
        # ìƒ˜í”Œ ë°ì´í„°ë¡œ SHAP ì‹œì—°
        data = load_sample_data()
        models = load_models()
        
        feature_cols = ['cast_pressure', 'upper_mold_temp1', 'lower_mold_temp1', 
                       'sleeve_temperature', 'Coolant_temperature']
        X_sample = data[feature_cols].iloc[:100]  # ìƒ˜í”Œ 100ê°œ
        
        try:
            # SHAP explainer ìƒì„± (ê°„ë‹¨í•œ ì‹œì—°ìš©)
            if hasattr(models['classification_model'], 'predict_proba'):
                # ê°„ë‹¨í•œ SHAP ê°’ ì‹œë®¬ë ˆì´ì…˜
                shap_values = np.random.normal(0, 0.01, (10, len(feature_cols)))
                
                # SHAP Summary Plot ìŠ¤íƒ€ì¼ ì°¨íŠ¸
                fig_shap = go.Figure()
                
                for i, feature in enumerate(feature_cols):
                    fig_shap.add_trace(go.Scatter(
                        x=shap_values[:, i],
                        y=[feature] * len(shap_values),
                        mode='markers',
                        marker=dict(
                            size=8,
                            color=X_sample.iloc[:10, i],
                            colorscale='RdYlBu',
                            showscale=True if i == 0 else False
                        ),
                        name=feature
                    ))
                
                fig_shap.update_layout(
                    title="SHAP Summary Plot - íŠ¹ì„± ê¸°ì—¬ë„ ë¶„ì„",
                    xaxis_title="SHAP ê°’ (í’ˆì§ˆì— ëŒ€í•œ ê¸°ì—¬ë„)",
                    height=400
                )
                st.plotly_chart(fig_shap, use_container_width=True)
                
                st.info("ğŸ” **í•´ì„:** ë¹¨ê°„ìƒ‰ì€ ë†’ì€ ê°’, íŒŒë€ìƒ‰ì€ ë‚®ì€ ê°’ì„ ì˜ë¯¸í•˜ë©°, "
                       "xì¶•ì€ í•´ë‹¹ íŠ¹ì„±ì´ í’ˆì§ˆ ì˜ˆì¸¡ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ë ¥ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.")
        except:
            st.warning("SHAP ë¶„ì„ì„ ìœ„í•´ì„œëŠ” ì¶”ê°€ ëª¨ë¸ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    
    with tab2:
        st.write("**Permutation Importance - íŠ¹ì„± ìˆœì—´ ì¤‘ìš”ë„**")
        
        # ì‹œë®¬ë ˆì´ì…˜ëœ ì¤‘ìš”ë„ ë°ì´í„°
        features = ['ì£¼ì¡°ì••ë ¥', 'ìƒë¶€ëª°ë“œì˜¨ë„', 'í•˜ë¶€ëª°ë“œì˜¨ë„', 'ìŠ¬ë¦¬ë¸Œì˜¨ë„', 'ëƒ‰ê°ìˆ˜ì˜¨ë„']
        importance_scores = [0.35, 0.22, 0.18, 0.15, 0.10]
        importance_std = [0.05, 0.03, 0.04, 0.02, 0.01]
        
        fig_perm = go.Figure()
        fig_perm.add_trace(go.Bar(
            x=features,
            y=importance_scores,
            error_y=dict(type='data', array=importance_std),
            marker_color='lightcoral',
            name='ì¤‘ìš”ë„'
        ))
        
        fig_perm.update_layout(
            title="Permutation Importance - íŠ¹ì„±ë³„ ì˜ˆì¸¡ ê¸°ì—¬ë„",
            xaxis_title="íŠ¹ì„±",
            yaxis_title="ì¤‘ìš”ë„ ì ìˆ˜",
            height=400
        )
        st.plotly_chart(fig_perm, use_container_width=True)
    
    with tab3:
        st.write("**PDP (Partial Dependence Plot) - ë¶€ë¶„ ì˜ì¡´ì„± í”Œë¡¯**")
        
        # ì„ íƒëœ íŠ¹ì„±ì— ëŒ€í•œ PDP
        selected_feature = st.selectbox("ë¶„ì„í•  íŠ¹ì„± ì„ íƒ", 
                                      ['ì£¼ì¡°ì••ë ¥', 'ìƒë¶€ëª°ë“œì˜¨ë„', 'ìŠ¬ë¦¬ë¸Œì˜¨ë„'])
        
        # PDP ì‹œë®¬ë ˆì´ì…˜
        if selected_feature == 'ì£¼ì¡°ì••ë ¥':
            x_vals = np.linspace(80, 200, 50)
            y_vals = 1 / (1 + np.exp(-(x_vals - 125) / 10))  # ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜
        elif selected_feature == 'ìƒë¶€ëª°ë“œì˜¨ë„':
            x_vals = np.linspace(180, 280, 50)
            y_vals = np.exp(-(x_vals - 225)**2 / 1000)  # ê°€ìš°ì‹œì•ˆ í•¨ìˆ˜
        else:
            x_vals = np.linspace(150, 400, 50)
            y_vals = np.maximum(0, 1 - (x_vals - 200) / 200)  # ì„ í˜• ê°ì†Œ
        
        fig_pdp = go.Figure()
        fig_pdp.add_trace(go.Scatter(
            x=x_vals,
            y=y_vals,
            mode='lines',
            line=dict(width=3, color='purple'),
            name='ë¶€ë¶„ ì˜ì¡´ì„±'
        ))
        
        fig_pdp.update_layout(
            title=f"PDP - {selected_feature}ì´ í’ˆì§ˆì— ë¯¸ì¹˜ëŠ” ì˜í–¥",
            xaxis_title=selected_feature,
            yaxis_title="ì˜ˆì¸¡ í™•ë¥ ",
            height=400
        )
        st.plotly_chart(fig_pdp, use_container_width=True)
    
    with tab4:
        st.write("**ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ**")
        
        # ì—¬ëŸ¬ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ (ì‹œë®¬ë ˆì´ì…˜)
        models_comparison = {
            'Random Forest': {'F1': 0.92, 'ROC-AUC': 0.95, 'Precision': 0.89, 'Recall': 0.95},
            'XGBoost': {'F1': 0.90, 'ROC-AUC': 0.93, 'Precision': 0.87, 'Recall': 0.93},
            'LightGBM': {'F1': 0.91, 'ROC-AUC': 0.94, 'Precision': 0.88, 'Recall': 0.94},
            'Logistic Regression': {'F1': 0.85, 'ROC-AUC': 0.88, 'Precision': 0.82, 'Recall': 0.88}
        }
        
        metrics_df = pd.DataFrame(models_comparison).T
        
        # ë ˆì´ë” ì°¨íŠ¸
        fig_radar = go.Figure()
        
        for model in metrics_df.index:
            fig_radar.add_trace(go.Scatterpolar(
                r=metrics_df.loc[model].values,
                theta=metrics_df.columns,
                fill='toself',
                name=model
            ))
        
        fig_radar.update_layout(
            polar=dict(
                radialaxis=dict(
                    visible=True,
                    range=[0, 1]
                )),
            showlegend=True,
            title="ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ (ë ˆì´ë” ì°¨íŠ¸)",
            height=500
        )
        st.plotly_chart(fig_radar, use_container_width=True)
        
        # ì„±ëŠ¥ í…Œì´ë¸”
        st.dataframe(metrics_df.round(3), use_container_width=True)

def create_realtime_monitoring():
    """ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ"""
    
    st.subheader("ğŸ“¡ ì‹¤ì‹œê°„ ê³µì • ëª¨ë‹ˆí„°ë§")
    
    # ì‹¤ì‹œê°„ ë°ì´í„° (ì‹œë®¬ë ˆì´ì…˜)
    data = load_sample_data()
    latest_data = data.tail(24)  # ìµœê·¼ 24ì‹œê°„
    
    # KPI ì¹´ë“œë“¤
    col1, col2, col3, col4 = st.columns(4)
    
    current_quality_rate = latest_data['quality'].mean()
    current_anomaly_count = len(latest_data) - int(current_quality_rate * len(latest_data))
    avg_cycle_time = latest_data['production_cycletime'].mean()
    efficiency = min(100, (40 / avg_cycle_time) * 100)  # ëª©í‘œ ì‚¬ì´í´ 40ì´ˆ ê¸°ì¤€
    
    with col1:
        st.markdown(f"""
        <div class="metric-card">
            <h4>âœ… í’ˆì§ˆ í•©ê²©ë¥ </h4>
            <h2>{current_quality_rate:.1%}</h2>
            <p>ìµœê·¼ 24ì‹œê°„</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown(f"""
        <div class="{'anomaly-card' if current_anomaly_count > 2 else 'metric-card'}">
            <h4>ğŸš¨ ì´ìƒ ê°ì§€ ê±´ìˆ˜</h4>
            <h2>{current_anomaly_count}ê±´</h2>
            <p>ìµœê·¼ 24ì‹œê°„</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown(f"""
        <div class="metric-card">
            <h4>â±ï¸ í‰ê·  ì‚¬ì´í´íƒ€ì„</h4>
            <h2>{avg_cycle_time:.1f}ì´ˆ</h2>
            <p>ëª©í‘œ: 40ì´ˆ</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col4:
        st.markdown(f"""
        <div class="{'normal-card' if efficiency > 90 else 'info-card'}">
            <h4>âš¡ ìƒì‚° íš¨ìœ¨ì„±</h4>
            <h2>{efficiency:.1f}%</h2>
            <p>ì‹¤ì‹œê°„ ê³„ì‚°</p>
        </div>
        """, unsafe_allow_html=True)
    
    # ì‹¤ì‹œê°„ íŠ¸ë Œë“œ ì°¨íŠ¸
    col1, col2 = st.columns(2)
    
    with col1:
        # í’ˆì§ˆ íŠ¸ë Œë“œ
        fig_quality = go.Figure()
        
        # 1ì‹œê°„ ë‹¨ìœ„ í’ˆì§ˆë¥  ê³„ì‚°
        hourly_quality = latest_data.groupby(latest_data['timestamp'].dt.hour)['quality'].mean()
        
        fig_quality.add_trace(go.Scatter(
            x=hourly_quality.index,
            y=hourly_quality.values,
            mode='lines+markers',
            line=dict(width=3, color='green'),
            marker=dict(size=8),
            name='í’ˆì§ˆ í•©ê²©ë¥ '
        ))
        
        fig_quality.add_hline(y=0.95, line_dash="dash", line_color="red", 
                             annotation_text="ëª©í‘œ 95%")
        
        fig_quality.update_layout(
            title="ğŸ“ˆ ì‹œê°„ë³„ í’ˆì§ˆ í•©ê²©ë¥  íŠ¸ë Œë“œ",
            xaxis_title="ì‹œê°„",
            yaxis_title="í•©ê²©ë¥ ",
            height=400
        )
        st.plotly_chart(fig_quality, use_container_width=True)
    
    with col2:
        # ì£¼ìš” ë³€ìˆ˜ íŠ¸ë Œë“œ
        fig_variables = go.Figure()
        
        # ì •ê·œí™”ëœ ì£¼ìš” ë³€ìˆ˜ë“¤
        variables = ['cast_pressure', 'upper_mold_temp1', 'sleeve_temperature']
        colors = ['blue', 'red', 'orange']
        
        for var, color in zip(variables, colors):
            normalized_vals = (latest_data[var] - latest_data[var].min()) / (latest_data[var].max() - latest_data[var].min())
            
            fig_variables.add_trace(go.Scatter(
                x=latest_data['timestamp'],
                y=normalized_vals,
                mode='lines',
                name=var,
                line=dict(color=color, width=2)
            ))
        
        fig_variables.update_layout(
            title="ğŸ“Š ì£¼ìš” ê³µì • ë³€ìˆ˜ íŠ¸ë Œë“œ (ì •ê·œí™”)",
            xaxis_title="ì‹œê°„",
            yaxis_title="ì •ê·œí™”ëœ ê°’",
            height=400
        )
        st.plotly_chart(fig_variables, use_container_width=True)
    
    # ìƒì„¸ ë°ì´í„° í…Œì´ë¸”
    if st.checkbox("ğŸ“‹ ìƒì„¸ ë°ì´í„° ë³´ê¸°"):
        st.subheader("ìµœê·¼ ê³µì • ë°ì´í„°")
        
        # ìµœê·¼ 10ê°œ ë°ì´í„°
        display_data = latest_data.tail(10).copy()
        display_data['í’ˆì§ˆ'] = display_data['quality'].map({1: 'âœ… ì–‘í’ˆ', 0: 'âŒ ë¶ˆëŸ‰'})
        display_data['ì‹œê°„'] = display_data['timestamp'].dt.strftime('%H:%M')
        
        display_cols = ['ì‹œê°„', 'í’ˆì§ˆ', 'cast_pressure', 'upper_mold_temp1', 
                       'sleeve_temperature', 'production_cycletime']
        
        st.dataframe(
            display_data[display_cols].round(2),
            use_container_width=True,
            height=400
        )

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    
    # í—¤ë”
    st.markdown("""
    <div class="main-header">
        <h1>ğŸ¤– AI ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ ì œì¡° í’ˆì§ˆê´€ë¦¬ ì‹œìŠ¤í…œ</h1>
        <p>ì‹¤ì‹œê°„ ì´ìƒ íƒì§€ â€¢ í’ˆì§ˆ ì˜ˆì¸¡ â€¢ ì„¤ëª… ê°€ëŠ¥í•œ AI â€¢ í†µí•© ëª¨ë‹ˆí„°ë§</p>
    </div>
    """, unsafe_allow_html=True)
    
    # ì‚¬ì´ë“œë°” ë©”ë‰´
    st.sidebar.header("ğŸ›ï¸ ì‹œìŠ¤í…œ ë©”ë‰´")
    page = st.sidebar.selectbox(
        "ë©”ë‰´ ì„ íƒ",
        ["ğŸ  ëŒ€ì‹œë³´ë“œ í™ˆ", "ğŸš¨ ì´ìƒ íƒì§€", "ğŸ¯ í’ˆì§ˆ ì˜ˆì¸¡", "ğŸ“Š ê³ ê¸‰ ë¶„ì„", "ğŸ“¡ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§"]
    )
    
    # ì‹œìŠ¤í…œ ìƒíƒœ
    st.sidebar.markdown("---")
    st.sidebar.markdown("### ğŸ”§ ì‹œìŠ¤í…œ ìƒíƒœ")
    st.sidebar.success("âœ… ëª¨ë¸ ì„œë²„: ì •ìƒ")
    st.sidebar.success("âœ… ë°ì´í„° ìˆ˜ì§‘: ì •ìƒ") 
    st.sidebar.success("âœ… ì´ìƒ íƒì§€: í™œì„±")
    st.sidebar.info(f"ğŸ• ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {datetime.now().strftime('%H:%M:%S')}")
    
    # ëª¨ë¸ ë¡œë“œ
    models = load_models()
    data = load_sample_data()
    
    # í˜ì´ì§€ë³„ ë‚´ìš©
    if page == "ğŸ  ëŒ€ì‹œë³´ë“œ í™ˆ":
        # ì¢…í•© ëŒ€ì‹œë³´ë“œ
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.subheader("ğŸ“Š ì‹¤ì‹œê°„ ì‹œìŠ¤í…œ í˜„í™©")
            
            # ì£¼ìš” ì§€í‘œë“¤
            quality_rate = data['quality'].tail(100).mean()
            avg_pressure = data['cast_pressure'].tail(24).mean()
            temp_variance = data[['upper_mold_temp1', 'lower_mold_temp1']].tail(24).var().mean()
            
            metrics_col1, metrics_col2, metrics_col3 = st.columns(3)
            
            with metrics_col1:
                st.metric("í’ˆì§ˆ í•©ê²©ë¥ ", f"{quality_rate:.1%}", "â†‘ 2.3%")
            with metrics_col2:
                st.metric("í‰ê·  ì£¼ì¡°ì••ë ¥", f"{avg_pressure:.1f}", "â†“ 5.2")
            with metrics_col3:
                st.metric("ì˜¨ë„ ì•ˆì •ì„±", f"{temp_variance:.1f}", "â†‘ 1.1")
        
        with col2:
            st.subheader("ğŸ¯ ì£¼ìš” ì•Œë¦¼")
            st.markdown("""
            <div class="info-card">
                <strong>ğŸ“ˆ í’ˆì§ˆ ê°œì„  ê¶Œê³ </strong><br>
                ì£¼ì¡°ì••ë ¥ì„ 120-130 ë²”ìœ„ë¡œ ì¡°ì •í•˜ì—¬ í’ˆì§ˆ í–¥ìƒ ê°€ëŠ¥
            </div>
            """, unsafe_allow_html=True)
            
            st.markdown("""
            <div class="normal-card">
                <strong>âœ… ì‹œìŠ¤í…œ ì •ìƒ</strong><br>
                ëª¨ë“  ì„¼ì„œê°€ ì •ìƒ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤
            </div>
            """, unsafe_allow_html=True)
        
        # ë¹ ë¥¸ í’ˆì§ˆ ì˜ˆì¸¡
        st.subheader("âš¡ ë¹ ë¥¸ í’ˆì§ˆ ì²´í¬")
        
        quick_col1, quick_col2, quick_col3, quick_col4 = st.columns(4)
        with quick_col1:
            q_pressure = st.number_input("ì£¼ì¡°ì••ë ¥", value=125.0)
        with quick_col2:
            q_temp = st.number_input("ìƒë¶€ì˜¨ë„", value=225.0)
        with quick_col3:
            q_sleeve = st.number_input("ìŠ¬ë¦¬ë¸Œì˜¨ë„", value=195.0)
        with quick_col4:
            if st.button("ğŸ” ë¹ ë¥¸ ì˜ˆì¸¡"):
                # ê°„ë‹¨í•œ ì˜ˆì¸¡ ë¡œì§
                risk_score = 0
                if q_pressure > 200 or q_pressure < 100: risk_score += 30
                if q_temp > 300 or q_temp < 180: risk_score += 25
                if q_sleeve > 400: risk_score += 45
                
                if risk_score > 50:
                    st.error("âš ï¸ ë¶ˆëŸ‰ ìœ„í—˜ ë†’ìŒ!")
                else:
                    st.success("âœ… ì–‘í’ˆ ì˜ˆìƒ")
    
    elif page == "ğŸš¨ ì´ìƒ íƒì§€":
        # ì´ìƒ íƒì§€ ëª¨ë¸ ìƒì„± ë° ì ìš©
        detector = AnomalyDetector()
        
        feature_cols = ['cast_pressure', 'upper_mold_temp1', 'lower_mold_temp1', 
                       'sleeve_temperature', 'Coolant_temperature']
        X = data[feature_cols]
        
        detector.fit(X)
        anomaly_results = detector.detect_anomalies(X)
        
        # ì´ìƒ íƒì§€ ìš”ì•½
        total_anomalies = sum(anomaly_results['is_anomaly'])
        anomaly_rate = total_anomalies / len(data) * 100
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ì´ ì´ìƒ ê±´ìˆ˜", total_anomalies)
        with col2:
            st.metric("ì´ìƒ íƒì§€ìœ¨", f"{anomaly_rate:.1f}%")
        with col3:
            latest_status = "ì´ìƒ" if anomaly_results['is_anomaly'][-1] else "ì •ìƒ"
            st.metric("í˜„ì¬ ìƒíƒœ", latest_status)
        
        # ì´ìƒ íƒì§€ ì°¨íŠ¸ë“¤
        fig1, fig2 = create_anomaly_detection_charts(data, anomaly_results)
        
        col1, col2 = st.columns(2)
        with col1:
            st.plotly_chart(fig1, use_container_width=True)
        with col2:
            st.plotly_chart(fig2, use_container_width=True)
        
        # ì´ìƒ íƒì§€ ìƒì„¸ ì •ë³´
        st.subheader("ğŸ” ì´ìƒ íƒì§€ ìƒì„¸ ë¶„ì„")
        
        method_col1, method_col2, method_col3 = st.columns(3)
        
        with method_col1:
            z_count = sum(anomaly_results['z_anomalies'])
            st.markdown(f"""
            <div class="metric-card">
                <h4>ğŸ“Š Z-Score ê¸°ë°˜</h4>
                <h3>{z_count}ê±´ íƒì§€</h3>
                <p>í†µê³„ì  ì´ìƒì¹˜ ê°ì§€</p>
            </div>
            """, unsafe_allow_html=True)
        
        with method_col2:
            iso_count = sum(anomaly_results['iso_anomalies'])
            st.markdown(f"""
            <div class="metric-card">
                <h4>ğŸŒ² Isolation Forest</h4>
                <h3>{iso_count}ê±´ íƒì§€</h3>
                <p>ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë°˜ ê°ì§€</p>
            </div>
            """, unsafe_allow_html=True)
        
        with method_col3:
            dbscan_count = sum(anomaly_results['dbscan_anomalies'])
            st.markdown(f"""
            <div class="metric-card">
                <h4>ğŸ¯ DBSCAN í´ëŸ¬ìŠ¤í„°ë§</h4>
                <h3>{dbscan_count}ê±´ íƒì§€</h3>
                <p>ë°€ë„ ê¸°ë°˜ ì´ìƒ ê°ì§€</p>
            </div>
            """, unsafe_allow_html=True)
    
    elif page == "ğŸ¯ í’ˆì§ˆ ì˜ˆì¸¡":
        create_quality_prediction_interface(models)
    
    elif page == "ğŸ“Š ê³ ê¸‰ ë¶„ì„":
        create_advanced_analytics()
    
    elif page == "ğŸ“¡ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§":
        create_realtime_monitoring()
    
    # í‘¸í„°
    st.markdown("---")
    st.markdown(f"""
    <div style='text-align: center; color: gray; margin-top: 2rem;'>
        <p>ğŸ¤– AI í’ˆì§ˆê´€ë¦¬ ì‹œìŠ¤í…œ v2.0 | 
        ğŸ“Š ì •í™•ë„: 98.86% | 
        ğŸ”„ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ | 
        â° {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()